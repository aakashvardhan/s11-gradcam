{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNxWCXxQrxnDodZe4eeCTQs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"lt8JTCuHwuz1","executionInfo":{"status":"ok","timestamp":1712923094635,"user_tz":-240,"elapsed":3,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["!git clone 'https://github.com/jacobgil/pytorch-grad-cam.git'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kahMpNCP9zm1","executionInfo":{"status":"ok","timestamp":1712923104847,"user_tz":-240,"elapsed":10215,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"95b11c60-6b23-4914-9a5e-76c13e086800"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pytorch-grad-cam'...\n","remote: Enumerating objects: 1168, done.\u001b[K\n","remote: Counting objects: 100% (70/70), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 1168 (delta 39), reused 32 (delta 19), pack-reused 1098\u001b[K\n","Receiving objects: 100% (1168/1168), 109.62 MiB | 19.57 MiB/s, done.\n","Resolving deltas: 100% (651/651), done.\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/pytorch-grad-cam')\n","sys.path.append('/content/pytorch-grad-cam/pytorch-grad-cam')"],"metadata":{"id":"w1T-xsQX95xl","executionInfo":{"status":"ok","timestamp":1712923104847,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Define the repository URL and the local directory where you want to clone/pull the repository\n","repo_url = 'https://github.com/aakashvardhan/s11-gradcam.git'\n","local_dir = '/content/s11-gradcam'\n","\n","\n","\n","# Check if the local directory already exists\n","if not os.path.exists(local_dir):\n","    # Clone the repository because it does not exist\n","    !git clone {repo_url}\n","else:\n","    # Change directory to the local repository\n","    %cd {local_dir}\n","    # Pull the latest changes because the repository already exists\n","    !git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tP3myM_fzjka","executionInfo":{"status":"ok","timestamp":1712923107846,"user_tz":-240,"elapsed":3002,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"d3664981-6325-4276-ad8c-cc0e2fea4c61"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 's11-gradcam'...\n","remote: Enumerating objects: 158, done.\u001b[K\n","remote: Counting objects: 100% (58/58), done.\u001b[K\n","remote: Compressing objects: 100% (41/41), done.\u001b[K\n","remote: Total 158 (delta 27), reused 45 (delta 17), pack-reused 100\u001b[K\n","Receiving objects: 100% (158/158), 40.62 MiB | 19.43 MiB/s, done.\n","Resolving deltas: 100% (68/68), done.\n"]}]},{"cell_type":"code","source":["sys.path.append('/content/s11-gradcam')\n","sys.path.append('/content/s11-gradcam/utils')"],"metadata":{"id":"CJZTpwcOzwYK","executionInfo":{"status":"ok","timestamp":1712923107846,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from models.resnet import ResNet18\n","from models.model_utils import model_summary\n","from main import set_seeds,setup_cifar10\n","from utils.misclassification import show_misclassified_images, plt_misclassified_images\n","from utils.gradcam import display_gradcam_output\n","from config import get_config\n","import torch\n","config = get_config()\n","set_seeds()"],"metadata":{"id":"eGWu-gUQzkBV","executionInfo":{"status":"ok","timestamp":1712923117201,"user_tz":-240,"elapsed":9358,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["_, _, _, test_loader = setup_cifar10(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13-dy3bb8_hL","executionInfo":{"status":"ok","timestamp":1712923122880,"user_tz":-240,"elapsed":5700,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"9a9d7399-270b-45be-cfd0-40c950fae0a7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available? True\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:02<00:00, 78461133.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["device = config[\"device\"]\n","model = ResNet18().to(device)\n","model_summary(model, input_size=(3, 32, 32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1kFYWtD82qw","executionInfo":{"status":"ok","timestamp":1712923124438,"user_tz":-240,"elapsed":1577,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"491a1bdb-c201-4c24-a257-6d09fc39a799"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","            Conv2d-3           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-4           [-1, 64, 32, 32]             128\n","            Conv2d-5           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","        BasicBlock-7           [-1, 64, 32, 32]               0\n","            Conv2d-8           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-9           [-1, 64, 32, 32]             128\n","           Conv2d-10           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-11           [-1, 64, 32, 32]             128\n","       BasicBlock-12           [-1, 64, 32, 32]               0\n","           Conv2d-13          [-1, 128, 16, 16]          73,728\n","      BatchNorm2d-14          [-1, 128, 16, 16]             256\n","           Conv2d-15          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-16          [-1, 128, 16, 16]             256\n","           Conv2d-17          [-1, 128, 16, 16]           8,192\n","      BatchNorm2d-18          [-1, 128, 16, 16]             256\n","       BasicBlock-19          [-1, 128, 16, 16]               0\n","           Conv2d-20          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-21          [-1, 128, 16, 16]             256\n","           Conv2d-22          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-23          [-1, 128, 16, 16]             256\n","       BasicBlock-24          [-1, 128, 16, 16]               0\n","           Conv2d-25            [-1, 256, 8, 8]         294,912\n","      BatchNorm2d-26            [-1, 256, 8, 8]             512\n","           Conv2d-27            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-28            [-1, 256, 8, 8]             512\n","           Conv2d-29            [-1, 256, 8, 8]          32,768\n","      BatchNorm2d-30            [-1, 256, 8, 8]             512\n","       BasicBlock-31            [-1, 256, 8, 8]               0\n","           Conv2d-32            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-33            [-1, 256, 8, 8]             512\n","           Conv2d-34            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-35            [-1, 256, 8, 8]             512\n","       BasicBlock-36            [-1, 256, 8, 8]               0\n","           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n","      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n","           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n","           Conv2d-41            [-1, 512, 4, 4]         131,072\n","      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n","       BasicBlock-43            [-1, 512, 4, 4]               0\n","           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n","           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n","       BasicBlock-48            [-1, 512, 4, 4]               0\n","           Linear-49                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,173,962\n","Trainable params: 11,173,962\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 11.25\n","Params size (MB): 42.63\n","Estimated Total Size (MB): 53.89\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load('/content/s11-gradcam/saved_models/model_gradcam_bn.pth'))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SFhC0TH59Ckg","executionInfo":{"status":"ok","timestamp":1712923124438,"user_tz":-240,"elapsed":8,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"f461ae87-5912-4e0d-ed50-af89f6a58528"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (linear): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["misclass_data = show_misclassified_images(model, test_loader, config)\n","plt_misclassified_images(config, misclass_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":598},"id":"fIQ5RmMqz2vv","executionInfo":{"status":"error","timestamp":1712923154238,"user_tz":-240,"elapsed":29805,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"ecf62180-e81a-42bf-ada4-bb51cdef8e06"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"error","ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-1daac915cfea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmisclass_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_misclassified_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt_misclassified_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmisclass_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/s11-gradcam/utils/misclassification.py\u001b[0m in \u001b[0;36mplt_misclassified_images\u001b[0;34m(config, misclass_data, max_images)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclass_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Prediction: {classes[pred]}\\nActual: {classes[label]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5663\u001b[0m                               **kwargs)\n\u001b[1;32m   5664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5665\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5666\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Needed e.g. to apply png palette.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         if (self._A.dtype != np.uint8 and\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_masked_invalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnative\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;31m# If we have already made a copy, do the byteswap in place, else make a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x400 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAJ8AAACgCAYAAAASN76YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACYElEQVR4nO3XsWrkMBRAUXlI60k/xP//YQF/wLgfbZV0wxo24bLJOa2EecXFkpY55xwQuNQD8HuJj4z4yIiPjPjIiI+M+MiIj8zLmU2Px2Ps+z7WdR3Lsnz3TPzn5pzjOI5xu93G5fL8/3Yqvn3fx7ZtXzYcv8P7+/t4e3t7un4qvnVdPz92vV6/ZjJ+rPv9PrZt++zmmVPxfRy11+tVfJz2tyuaBwcZ8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkREfGfGRER8Z8ZERHxnxkXk5s2nOOcYY436/f+sw/AwfnXx088yp+I7jGGOMsW3bP47Fb3Icx3h9fX26vsy/5TnGeDweY9/3sa7rWJblSwfk55lzjuM4xu12G5fL85vdqfjgO3hwkBEfGfGRER8Z8ZERHxnxkfkDvjdDyHQmllkAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":["!pip install ttach"],"metadata":{"id":"sNpr1wLf_w_B","executionInfo":{"status":"aborted","timestamp":1712923154239,"user_tz":-240,"elapsed":3,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_layers = [model.layer4[-1]]\n","display_gradcam_output(misclass_data,config['classes'],model,target_layers)"],"metadata":{"id":"hd5KwpQZ-8cb","executionInfo":{"status":"aborted","timestamp":1712923154239,"user_tz":-240,"elapsed":3,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nfsdKDp0_Tpy","executionInfo":{"status":"aborted","timestamp":1712923154239,"user_tz":-240,"elapsed":2,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNxWCXxQrxnDodZe4eeCTQs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"lt8JTCuHwuz1","executionInfo":{"status":"ok","timestamp":1712922080707,"user_tz":-240,"elapsed":8,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["!git clone 'https://github.com/jacobgil/pytorch-grad-cam.git'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kahMpNCP9zm1","executionInfo":{"status":"ok","timestamp":1712922080708,"user_tz":-240,"elapsed":8,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"6b25f426-3b81-4410-a527-1d7e86da9f61"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'pytorch-grad-cam' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/pytorch-grad-cam')\n","sys.path.append('/content/pytorch-grad-cam/pytorch-grad-cam')"],"metadata":{"id":"w1T-xsQX95xl","executionInfo":{"status":"ok","timestamp":1712922080708,"user_tz":-240,"elapsed":6,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# Define the repository URL and the local directory where you want to clone/pull the repository\n","repo_url = 'https://github.com/aakashvardhan/s11-gradcam.git'\n","local_dir = '/content/s11-gradcam'\n","\n","\n","\n","# Check if the local directory already exists\n","if not os.path.exists(local_dir):\n","    # Clone the repository because it does not exist\n","    !git clone {repo_url}\n","else:\n","    # Change directory to the local repository\n","    %cd {local_dir}\n","    # Pull the latest changes because the repository already exists\n","    !git pull"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tP3myM_fzjka","executionInfo":{"status":"ok","timestamp":1712922082099,"user_tz":-240,"elapsed":1396,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"565546e1-b873-4724-982b-a2d3cbf08441"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/s11-gradcam\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 6 (delta 3), reused 6 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (6/6), 1.19 KiB | 406.00 KiB/s, done.\n","From https://github.com/aakashvardhan/s11-gradcam\n","   993274d..f1668f9  main       -> origin/main\n","Updating 993274d..f1668f9\n","Fast-forward\n"," notebooks/show_gradcam_output.ipynb | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n"," utils/misclassification.py          | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n"," 2 files changed, 2 insertions(+), 2 deletions(-)\n"]}]},{"cell_type":"code","source":["sys.path.append('/content/s11-gradcam')\n","sys.path.append('/content/s11-gradcam/utils')"],"metadata":{"id":"CJZTpwcOzwYK","executionInfo":{"status":"ok","timestamp":1712922082099,"user_tz":-240,"elapsed":17,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from models.resnet import ResNet18\n","from models.model_utils import model_summary\n","from main import set_seeds,setup_cifar10\n","from utils.misclassification import show_misclassified_images, plt_misclassified_images\n","from utils.gradcam import display_gradcam_output\n","from config import get_config\n","import torch\n","config = get_config()\n","set_seeds()"],"metadata":{"id":"eGWu-gUQzkBV","executionInfo":{"status":"ok","timestamp":1712922086243,"user_tz":-240,"elapsed":4161,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["_, _, _, test_loader = setup_cifar10(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13-dy3bb8_hL","executionInfo":{"status":"ok","timestamp":1712922087701,"user_tz":-240,"elapsed":1462,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"f695cacb-06c0-4361-9e2a-d6e85729618b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available? True\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["device = config[\"device\"]\n","model = ResNet18().to(device)\n","model_summary(model, input_size=(3, 32, 32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1kFYWtD82qw","executionInfo":{"status":"ok","timestamp":1712922088715,"user_tz":-240,"elapsed":1016,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"a5b03bb3-bf64-4a85-bb4a-caf081699213"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,728\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","            Conv2d-3           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-4           [-1, 64, 32, 32]             128\n","            Conv2d-5           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-6           [-1, 64, 32, 32]             128\n","        BasicBlock-7           [-1, 64, 32, 32]               0\n","            Conv2d-8           [-1, 64, 32, 32]          36,864\n","       BatchNorm2d-9           [-1, 64, 32, 32]             128\n","           Conv2d-10           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-11           [-1, 64, 32, 32]             128\n","       BasicBlock-12           [-1, 64, 32, 32]               0\n","           Conv2d-13          [-1, 128, 16, 16]          73,728\n","      BatchNorm2d-14          [-1, 128, 16, 16]             256\n","           Conv2d-15          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-16          [-1, 128, 16, 16]             256\n","           Conv2d-17          [-1, 128, 16, 16]           8,192\n","      BatchNorm2d-18          [-1, 128, 16, 16]             256\n","       BasicBlock-19          [-1, 128, 16, 16]               0\n","           Conv2d-20          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-21          [-1, 128, 16, 16]             256\n","           Conv2d-22          [-1, 128, 16, 16]         147,456\n","      BatchNorm2d-23          [-1, 128, 16, 16]             256\n","       BasicBlock-24          [-1, 128, 16, 16]               0\n","           Conv2d-25            [-1, 256, 8, 8]         294,912\n","      BatchNorm2d-26            [-1, 256, 8, 8]             512\n","           Conv2d-27            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-28            [-1, 256, 8, 8]             512\n","           Conv2d-29            [-1, 256, 8, 8]          32,768\n","      BatchNorm2d-30            [-1, 256, 8, 8]             512\n","       BasicBlock-31            [-1, 256, 8, 8]               0\n","           Conv2d-32            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-33            [-1, 256, 8, 8]             512\n","           Conv2d-34            [-1, 256, 8, 8]         589,824\n","      BatchNorm2d-35            [-1, 256, 8, 8]             512\n","       BasicBlock-36            [-1, 256, 8, 8]               0\n","           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n","      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n","           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n","           Conv2d-41            [-1, 512, 4, 4]         131,072\n","      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n","       BasicBlock-43            [-1, 512, 4, 4]               0\n","           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n","           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n","      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n","       BasicBlock-48            [-1, 512, 4, 4]               0\n","           Linear-49                   [-1, 10]           5,130\n","================================================================\n","Total params: 11,173,962\n","Trainable params: 11,173,962\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 11.25\n","Params size (MB): 42.63\n","Estimated Total Size (MB): 53.89\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["model.load_state_dict(torch.load('/content/s11-gradcam/saved_models/model_gradcam_bn.pth'))\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SFhC0TH59Ckg","executionInfo":{"status":"ok","timestamp":1712922088715,"user_tz":-240,"elapsed":8,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"e56ab0f6-42e8-4ac1-b7db-aa2b7dd8db26"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (shortcut): Sequential()\n","    )\n","  )\n","  (linear): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["misclass_data = show_misclassified_images(model, test_loader, config)\n","plt_misclassified_images(config, misclass_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574},"id":"fIQ5RmMqz2vv","executionInfo":{"status":"error","timestamp":1712922120502,"user_tz":-240,"elapsed":31792,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}},"outputId":"a5858a98-6e44-423d-a6b1-964c3739ec3b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"error","ename":"IndexError","evalue":"invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-1daac915cfea>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmisclass_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_misclassified_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt_misclassified_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmisclass_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/s11-gradcam/utils/misclassification.py\u001b[0m in \u001b[0;36mplt_misclassified_images\u001b[0;34m(config, misclass_data, max_images)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclass_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclass_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmisclass_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 2000x400 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAR8AAACgCAYAAAA1vGhZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACwklEQVR4nO3YMW7bQBBA0aXglnIvmPc/mAEeQOy1qZxSIRA7H3beqwfEVB/LWeaccwD8Y5d6AeD/JD5AQnyAhPgACfEBEuIDJMQHSIgPkHg5M/R4PMa+72Nd17Esy1fvBHxTc85xHMe43W7jcnn+tjkVn33fx7Ztn7Ic8PO9v7+Pt7e3pzOn4rOu6+8PXq/Xv98M+JHu9/vYtu13M545FZ+PX63r9So+wB+dOc84OAMJ8QES4gMkxAdIiA+QEB8gIT5AQnyAhPgACfEBEuIDJMQHSIgPkBAfICE+QEJ8gIT4AAnxARLiAyTEB0iID5AQHyAhPkBCfICE+AAJ8QES4gMkxAdIiA+QEB8gIT5AQnyAhPgACfEBEuIDJMQHSIgPkBAfICE+QEJ8gIT4AAnxARLiAyTEB0iID5AQHyAhPkBCfICE+AAJ8QES4gMkxAdIiA+QEB8gIT5AQnyAhPgACfEBEuIDJMQHSIgPkBAfICE+QEJ8gIT4AAnxARLiAyTEB0iID5AQHyAhPkBCfICE+AAJ8QES4gMkxAdIiA+QEB8gIT5AQnyAhPgACfEBEuIDJMQHSIgPkBAfICE+QEJ8gIT4AAnxARLiAyTEB0iID5AQHyAhPkBCfICE+AAJ8QES4gMkxAdIiA+QEB8gIT5AQnyAhPgACfEBEuIDJMQHSIgPkBAfICE+QEJ8gIT4AAnxARLiAyTEB0iID5AQHyAhPkBCfICE+AAJ8QES4gMkxAdIiA+QEB8gIT5AQnyAhPgACfEBEuIDJMQHSIgPkBAfICE+QEJ8gMTLmaE55xhjjPv9/qXLAN/bRyM+mvHMqfgcxzHGGGPbtr9YC/hfHMcxXl9fn84s80SiHo/H2Pd9rOs6lmX5tAWBn2XOOY7jGLfbbVwuz686p+ID8NkcnIGE+AAJ8QES4gMkxAdIiA+QEB8g8Qv9gEPIjqxV3gAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":["!pip install ttach"],"metadata":{"id":"sNpr1wLf_w_B","executionInfo":{"status":"aborted","timestamp":1712922120503,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_layers = [model.layer4[-1]]\n","display_gradcam_output(misclass_data,config['classes'],model,target_layers)"],"metadata":{"id":"hd5KwpQZ-8cb","executionInfo":{"status":"aborted","timestamp":1712922120503,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nfsdKDp0_Tpy","executionInfo":{"status":"aborted","timestamp":1712922120503,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aakash Vardhan","userId":"03146811293329168388"}}},"execution_count":null,"outputs":[]}]}